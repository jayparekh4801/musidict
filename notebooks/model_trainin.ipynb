{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/jparekh4/musidict/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [rank: 0] Seed set to 7\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from src.components import data_ingestion\n",
    "from src.components import data_transformation\n",
    "from src.components import data_loading\n",
    "from src import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"../data/raw_data/npz_files_10377.npz\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data_ingestion.DataIngestion().initiate_data_ingestion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, transformed_data = data_transformation.DataTransformation().initiate_data_transformation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(transformed_data[:, -3:].astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"genre\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.column_stack((transformed_data, dataset[\"genre\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[:,14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Example numpy array with dtype=object and some 2D arrays\n",
    "# data = np.array([\n",
    "#     [1, 2, 3, np.array([[1, 2], [3, 4]])],\n",
    "#     [4, 5, 6, np.array([[5, 6], [7, 8]])],\n",
    "#     [7, 8, 9, np.array([[9, 10], [11, 12]])]\n",
    "# ], dtype=object)\n",
    "\n",
    "# Step 1: Flatten 2D arrays into 1D arrays\n",
    "flattened_data = []\n",
    "for row in transformed_data:\n",
    "    flattened_row = []\n",
    "    for value in row:\n",
    "        if isinstance(value, np.ndarray):  # Check if value is a 2D array\n",
    "            flattened_row.extend(value.flatten())  # Flatten the 2D array and add to list\n",
    "        else:\n",
    "            flattened_row.append(value)  # Keep the scalar as is\n",
    "    flattened_data.append(flattened_row)\n",
    "\n",
    "# Step 2: Convert the flattened data to a numpy array with a numeric dtype\n",
    "flattened_data = np.array(flattened_data, dtype=np.float32)\n",
    "\n",
    "# Step 3: Convert the numpy array to a PyTorch tensor\n",
    "tensor_data = torch.tensor(flattened_data)\n",
    "\n",
    "print(tensor_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randn(8, 13, 937)  # Example shape (8 samples, 128, 937)\n",
    "b = np.random.randn(8, 13, 937)\n",
    "c = np.random.randn(8, 13, 937)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([\"hi\"]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = np.array([c, a, b])\n",
    "rows = np.array([row, row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {\n",
    "    'mel_spectrogram': np.random.randn(10, 128, 937),\n",
    "    'mfccs': np.random.randn(10, 13, 937),\n",
    "    'chroma': np.random.randn(10, 12, 937),\n",
    "    'spectral_contrast': np.random.randn(10, 7, 937),\n",
    "    'zcr': np.random.randn(10, 1, 937),\n",
    "    'spectral_centroid': np.random.randn(10, 1, 937),\n",
    "    'spectral_bandwidth': np.random.randn(10, 1, 937),\n",
    "    'rms_energy': np.random.randn(10, 1, 937),\n",
    "    'tonnetz': np.random.randn(10, 6, 937),\n",
    "}\n",
    "\n",
    "# Bit rate and duration as scalar values\n",
    "bit_rate = np.random.rand(10)\n",
    "duration = np.random.rand(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Sample categorical data\n",
    "genres = ['pop', 'rock', 'jazz', 'classical'] * 2 + ['pop', 'classical']  # 1000 samples\n",
    "song_success = ['hit', 'flop', \"can't say\"] * 3 + ['hit']  # 1000 samples\n",
    "\n",
    "# One-hot encode genres\n",
    "genre_encoder = OneHotEncoder(sparse=False)\n",
    "genres_encoded = genre_encoder.fit_transform(np.array(genres).reshape(-1, 1))  # Shape: (1000, num_genres)\n",
    "\n",
    "# One-hot encode song success\n",
    "success_encoder = OneHotEncoder(sparse=False)\n",
    "success_encoded = success_encoder.fit_transform(np.array(song_success).reshape(-1, 1))  # Shape: (1000, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_2d = StandardScaler()\n",
    "scaler_scalar = StandardScaler()\n",
    "\n",
    "# Example standardization for each 2D time-series feature\n",
    "features_scaled = {}\n",
    "for feature_name, feature_data in features.items():\n",
    "    # Flatten, scale, then reshape\n",
    "    flat_feature = feature_data.reshape(-1, feature_data.shape[-1])  # Shape: (N*D, T)\n",
    "    scaled_flat_feature = scaler_2d.fit_transform(flat_feature)\n",
    "    features_scaled[feature_name] = scaled_flat_feature.reshape(feature_data.shape)\n",
    "\n",
    "# Example scaling for scalar features\n",
    "bit_rate_scaled = scaler_scalar.fit_transform(bit_rate.reshape(-1, 1)).flatten()\n",
    "duration_scaled = scaler_scalar.fit_transform(duration.reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class MusicDataset(Dataset):\n",
    "    def __init__(self, scaled_features, genre_one_hot, bit_rate_scaled, duration_scaled, targets_one_hot):\n",
    "        self.features = scaled_features\n",
    "        self.genre_one_hot = genre_one_hot.astype(np.float32)\n",
    "        self.bit_rate = bit_rate_scaled.astype(np.float32)\n",
    "        self.duration = duration_scaled.astype(np.float32)\n",
    "        self.targets = targets_one_hot.astype(np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'mel_spectrogram': torch.tensor(self.features['mel_spectrogram'][idx], dtype=torch.float32),\n",
    "            'mfccs': torch.tensor(self.features['mfccs'][idx], dtype=torch.float32),\n",
    "            'chroma': torch.tensor(self.features['chroma'][idx], dtype=torch.float32),\n",
    "            'spectral_contrast': torch.tensor(self.features['spectral_contrast'][idx], dtype=torch.float32),\n",
    "            'zcr': torch.tensor(self.features['zcr'][idx], dtype=torch.float32),\n",
    "            'spectral_centroid': torch.tensor(self.features['spectral_centroid'][idx], dtype=torch.float32),\n",
    "            'spectral_bandwidth': torch.tensor(self.features['spectral_bandwidth'][idx], dtype=torch.float32),\n",
    "            'rms_energy': torch.tensor(self.features['rms_energy'][idx], dtype=torch.float32),\n",
    "            'tonnetz': torch.tensor(self.features['tonnetz'][idx], dtype=torch.float32),\n",
    "            'bit_rate': torch.tensor(self.bit_rate[idx], dtype=torch.float32),\n",
    "            'duration': torch.tensor(self.duration[idx], dtype=torch.float32),\n",
    "            'genre': torch.tensor(self.genre_one_hot[idx], dtype=torch.float32),\n",
    "            'target': torch.tensor(self.targets[idx], dtype=torch.float32),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "dataset = MusicDataset(features_scaled, genres_encoded, bit_rate_scaled, duration_scaled, success_encoded)\n",
    "\n",
    "# DataLoader with batch size\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in dataloader:\n",
    "    print(b)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = np.array([[0], [2 ,3 ]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = np.array([row, row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(transformed_data[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = torch.tensor(transformed_data[:, 1].astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second = torch.tensor(np.stack(transformed_data[:, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_tensor_expanded = first.view(-1, 1, 1)  # Make each scalar a 1x1 matrix\n",
    "first = scalar_tensor_expanded.expand(-1, *second.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = torch.cat((first, second), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Sample DataLoader for Music Dataset (Assumes you already have the data loaded)\n",
    "class MusicDataset(Dataset):\n",
    "    def __init__(self, features, targets, genres, bit_rate, duration):\n",
    "        self.features = features  # Dictionary with all feature arrays\n",
    "        self.targets = targets    # One-hot encoded target\n",
    "        self.genres = genres      # Indices for genres\n",
    "        self.bit_rate = bit_rate\n",
    "        self.duration = duration\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mel_spectrogram = torch.tensor(self.features['mel_spectrogram'][idx], dtype=torch.float32)\n",
    "        mfccs = torch.tensor(self.features['mfccs'][idx], dtype=torch.float32)\n",
    "        chroma = torch.tensor(self.features['chroma'][idx], dtype=torch.float32)\n",
    "        spectral_contrast = torch.tensor(self.features['spectral_contrast'][idx], dtype=torch.float32)\n",
    "        zcr = torch.tensor(self.features['zcr'][idx], dtype=torch.float32)\n",
    "        spectral_centroid = torch.tensor(self.features['spectral_centroid'][idx], dtype=torch.float32)\n",
    "        spectral_bandwidth = torch.tensor(self.features['spectral_bandwidth'][idx], dtype=torch.float32)\n",
    "        rms_energy = torch.tensor(self.features['rms_energy'][idx], dtype=torch.float32)\n",
    "        tonnetz = torch.tensor(self.features['tonnetz'][idx], dtype=torch.float32)\n",
    "\n",
    "        # Scalar features\n",
    "        bit_rate = torch.tensor(self.bit_rate[idx], dtype=torch.float32).unsqueeze(0)\n",
    "        duration = torch.tensor(self.duration[idx], dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        # Categorical features (genre as an index)\n",
    "        genre = torch.tensor(self.genres[idx], dtype=torch.long)\n",
    "        target = torch.tensor(self.targets[idx], dtype=torch.float32)  # One-hot encoded target\n",
    "\n",
    "        return {\n",
    "            'mel_spectrogram': mel_spectrogram,\n",
    "            'mfccs': mfccs,\n",
    "            'chroma': chroma,\n",
    "            'spectral_contrast': spectral_contrast,\n",
    "            'zcr': zcr,\n",
    "            'spectral_centroid': spectral_centroid,\n",
    "            'spectral_bandwidth': spectral_bandwidth,\n",
    "            'rms_energy': rms_energy,\n",
    "            'tonnetz': tonnetz,\n",
    "            'bit_rate': bit_rate,\n",
    "            'duration': duration,\n",
    "            'genre': genre,\n",
    "            'target': target\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features['mel_spectrogram'])\n",
    "\n",
    "# Define the model for predicting song success\n",
    "class MusicSuccessPredictor(nn.Module):\n",
    "    def __init__(self, genre_size=10, genre_embedding_dim=4):\n",
    "        super(MusicSuccessPredictor, self).__init__()\n",
    "\n",
    "        # Embedding for genres (10 genres, embedding dim 4)\n",
    "        self.genre_embedding = nn.Embedding(genre_size, genre_embedding_dim)\n",
    "\n",
    "        # Convolutional layers for mel_spectrogram\n",
    "        self.conv_mel = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2))\n",
    "        )\n",
    "\n",
    "        # Linear layers for scalar features (bit_rate, duration, and genre embedding)\n",
    "        self.scalar_fc = nn.Linear(2 + genre_embedding_dim, 16)  # bit_rate + duration + genre embedding\n",
    "\n",
    "        # Fully connected layers for output\n",
    "        self.fc1 = nn.Linear(16 + 16, 64)  # Combine features from the CNN and scalar features\n",
    "        self.fc2 = nn.Linear(64, 3)  # 3 categories for output (hit, flop, can't say)\n",
    "        self.softmax = nn.Softmax(dim=1)  # Softmax activation for classification\n",
    "\n",
    "    def forward(self, mel_spectrogram, mfccs, chroma, spectral_contrast, zcr, spectral_centroid,\n",
    "                spectral_bandwidth, rms_energy, tonnetz, bit_rate, duration, genre):\n",
    "\n",
    "        # Embedding for genre\n",
    "        genre_embedding = self.genre_embedding(genre)  # Shape: (batch_size, genre_embedding_dim)\n",
    "\n",
    "        # Process mel_spectrogram with CNN\n",
    "        mel_spectrogram = mel_spectrogram.unsqueeze(1)  # Add channel dimension for Conv2d\n",
    "        mel_features = self.conv_mel(mel_spectrogram)\n",
    "        mel_features = torch.flatten(mel_features, start_dim=1)\n",
    "\n",
    "        # Combine scalar features with genre embedding\n",
    "        scalar_features = torch.cat([bit_rate, duration, genre_embedding], dim=1)\n",
    "        scalar_features = self.scalar_fc(scalar_features)\n",
    "\n",
    "        # Combine CNN features and scalar features, pass through fully connected layers\n",
    "        combined_features = torch.cat([mel_features, scalar_features], dim=1)\n",
    "        x = self.fc1(combined_features)\n",
    "        x = torch.relu(x)  # Apply activation function\n",
    "        output = self.fc2(x)  # Output layer with 3 categories\n",
    "\n",
    "        # Softmax for classification\n",
    "        output = self.softmax(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "# Data preparation\n",
    "# Assuming you have features and labels as numpy arrays and one-hot encoded target\n",
    "features = {\n",
    "    'mel_spectrogram': np.random.rand(1000, 128, 937),  # Example shape: (num_samples, 128, 937)\n",
    "    'mfccs': np.random.rand(1000, 13, 937),\n",
    "    'chroma': np.random.rand(1000, 12, 937),\n",
    "    'spectral_contrast': np.random.rand(1000, 7, 937),\n",
    "    'zcr': np.random.rand(1000, 1, 937),\n",
    "    'spectral_centroid': np.random.rand(1000, 1, 937),\n",
    "    'spectral_bandwidth': np.random.rand(1000, 1, 937),\n",
    "    'rms_energy': np.random.rand(1000, 1, 937),\n",
    "    'tonnetz': np.random.rand(1000, 6, 937)\n",
    "}\n",
    "bit_rate = np.random.rand(1000)  # Scalar feature\n",
    "duration = np.random.rand(1000)  # Scalar feature\n",
    "genres = np.random.randint(0, 10, 1000)  # Integer indices for genres (10 genres)\n",
    "targets = np.random.randint(0, 3, 1000)  # Example target labels: 0=hit, 1=flop, 2=can't say\n",
    "\n",
    "# One-hot encoding the target\n",
    "targets_onehot = np.eye(3)[targets]\n",
    "\n",
    "# Create Dataset and DataLoader\n",
    "dataset = MusicDataset(features, targets_onehot, genres, bit_rate, duration)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# # Model initialization\n",
    "# model = MusicSuccessPredictor()\n",
    "\n",
    "# # Loss function and optimizer\n",
    "# loss_fn = nn.CrossEntropyLoss()  # Cross-entropy loss for multi-class classification\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# # Training Loop\n",
    "# num_epochs = 10\n",
    "# for epoch in range(num_epochs):\n",
    "#     for batch in dataloader:\n",
    "#         mel_spectrogram = batch['mel_spectrogram']\n",
    "#         mfccs = batch['mfccs']\n",
    "#         chroma = batch['chroma']\n",
    "#         spectral_contrast = batch['spectral_contrast']\n",
    "#         zcr = batch['zcr']\n",
    "#         spectral_centroid = batch['spectral_centroid']\n",
    "#         spectral_bandwidth = batch['spectral_bandwidth']\n",
    "#         rms_energy = batch['rms_energy']\n",
    "#         tonnetz = batch['tonnetz']\n",
    "#         bit_rate = batch['bit_rate']\n",
    "#         duration = batch['duration']\n",
    "#         genre = batch['genre']\n",
    "#         target = batch['target']  # One-hot encoded target\n",
    "\n",
    "#         # Zero gradients\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # Forward pass\n",
    "#         outputs = model(mel_spectrogram, mfccs, chroma, spectral_contrast, zcr,\n",
    "#                         spectral_centroid, spectral_bandwidth, rms_energy, tonnetz,\n",
    "#                         bit_rate, duration, genre)\n",
    "\n",
    "#         # Loss calculation\n",
    "#         loss = loss_fn(outputs, torch.max(target, 1)[1])  # Cross-entropy loss with one-hot target\n",
    "\n",
    "#         # Backward pass and optimization\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#     print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "# # Save the model after training\n",
    "# torch.save(model.state_dict(), 'music_success_predictor.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"mel_spectrogram\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = utils.convert_dataset_into_tensor_dict(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(np.stack(transformed_data[:, 1]) ,dtype=torch.flo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['mel_spectrogram'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"success\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = np.random.randint(0, 3, 1000)  # Example target labels: 0=hit, 1=flop, 2=can't say\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_onehot = np.eye(3)[targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(targets_onehot).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data_loading.DataModule(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.load_and_split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = a.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in t:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i['mel_spectrogram'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.components import model_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Create a 2x3 tensor\n",
    "input_tensor = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "\n",
    "# Apply softmax along dim=0 (rows)\n",
    "softmax_dim0 = torch.softmax(input_tensor, dim=0)\n",
    "print(\"Softmax along dim=0:\\n\", softmax_dim0)\n",
    "\n",
    "# Apply softmax along dim=1 (columns)\n",
    "softmax_dim1 = torch.softmax(input_tensor, dim=1)\n",
    "print(\"Softmax along dim=1:\\n\", softmax_dim1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_obj = data_loading.DataModule(batch_size=2)\n",
    "# data_ingestion.DataIngestion().initiate_data_ingestion()\n",
    "train_loader = data_loader_obj.train_dataloader()\n",
    "val_loader = data_loader_obj.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vb in val_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vb[\"bit_rate\"]\n",
    "# print(batch['bit_rate'].float(),   # Scalar (batch_size, 1)\n",
    "#                 batch['duration'].float(),   # Scalar (batch_size, 1)\n",
    "#                 batch['genre'].float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vb[\"duration\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vb[\"genre\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_dataset = np.load(\"/Users/jayparekh/Documents/projects/musidict/data/transformed_data/transformed_dataset.npy\", allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_dataset[:, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_dataset[:, 2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_dash = utils.convert_dataset_into_tensor_dict(t_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_dash[\"genre\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_dash[\"duration\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(t_dash[\"bit_rate\"], dtype=torch.float32).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_dash[\"bit_rate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "L.seed_everything(7, workers=True)\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n",
    "from src.components import model_trainer\n",
    "\n",
    "batch_size = 2\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "dropout_prob = 0.3\n",
    "lr_logger = LearningRateMonitor()\n",
    "early_stopping = EarlyStopping('val_loss_mean', mode='min', patience=10)\n",
    "model_checkpoint = ModelCheckpoint(dirpath=\"../artifacts/MODELS\",save_last=True, save_top_k=3, monitor=\"val_loss_mean\")\n",
    "epochs = 10\n",
    "data_loader_obj = data_loading.DataModule(batch_size=batch_size)\n",
    "# data_ingestion.DataIngestion().initiate_data_ingestion()\n",
    "train_loader = data_loader_obj.train_dataloader()\n",
    "val_loader = data_loader_obj.val_dataloader()\n",
    "\n",
    "lightning_model = model_trainer.MusicSuccessPredictor(loss_fn=criterion, learning_rate=learning_rate, dropout_prob=dropout_prob)\n",
    "\n",
    "trainer = L.Trainer(max_epochs=epochs, callbacks=[lr_logger, early_stopping, model_checkpoint])\n",
    "\n",
    "trainer.fit(lightning_model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_dash[\"mfccs\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_dash[\"mfccs\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_dash[\"mfccs\"][0].unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ingestion.DataIngestion().initiate_data_ingestion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [\"ara\", 1 , np.array([[1, 2], [2, 3]])]\n",
    "b = [1 , np.array([[1, 2], [2, 3]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = [a, b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d =np.stack(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dataset = []\n",
    "# logging.info(\"Data Ingestion Started.\")\n",
    "for filename in os.listdir(\"../data/raw_data\"):\n",
    "    data_point = []\n",
    "    if filename.endswith('.npz'):\n",
    "        file_path = os.path.join(\"../data/raw_data\", filename)\n",
    "        data = np.load(file_path, allow_pickle=True)\n",
    "        genre = utils.preprocess_genres(data[\"metadata\"][0][\"genres\"])\n",
    "        if not genre:\n",
    "            continue\n",
    "        data_point.append(genre)\n",
    "        data_point.append(data[\"metadata\"][0][\"bit_rate\"])\n",
    "        data_point.append(data[\"metadata\"][0][\"duration\"])\n",
    "        data_point.append(utils.categorize_listens(data[\"metadata\"][0][\"listens\"]))\n",
    "        \n",
    "\n",
    "        data = utils.reshape_all_time_series_data(data)\n",
    "        data_point.append(data[\"mel_spectrogram\"])\n",
    "        data_point.append(data[\"mfccs\"])\n",
    "        data_point.append(data[\"chroma\"])\n",
    "        data_point.append(data[\"spectral_contrast\"])\n",
    "        data_point.append(data[\"zcr\"])\n",
    "        data_point.append(data[\"spectral_centroid\"])\n",
    "        data_point.append(data[\"spectral_bandwidth\"])\n",
    "        data_point.append(data[\"rms_energy\"])\n",
    "        data_point.append(data[\"tonnetz\"])\n",
    "        print(data_point)\n",
    "    dataset.append(data_point)\n",
    "print(len(dataset))\n",
    "dataset = np.stack(dataset)\n",
    "print(dataset.shape)\n",
    "dataset_df = pd.DataFrame(dataset, columns=[\n",
    "    \"genre\",\n",
    "    \"bit_rate\",\n",
    "    \"duration\",\n",
    "    \"success\",\n",
    "    \"mel_spectrogram\",\n",
    "    \"mfccs\",\n",
    "    \"chroma\",\n",
    "    \"spectral_contrast\",\n",
    "    \"zcr\",\n",
    "    \"spectral_centroid\",\n",
    "    \"spectral_bandwidth\",\n",
    "    \"rms_energy\",\n",
    "    \"tonnetz\",\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [rank: 0] Seed set to 7\n"
     ]
    }
   ],
   "source": [
    "dm = data_loading.DataModule(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = dm.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mel_spectrogram': tensor([[[[-2.0870e-01, -1.6125e-01, -1.3827e-01,  ..., -1.2600e-01,\n",
       "            -1.2688e-01, -1.3345e-01],\n",
       "           [-2.0928e-01, -1.6126e-01, -1.3803e-01,  ..., -1.2592e-01,\n",
       "            -1.2682e-01, -1.3044e-01],\n",
       "           [-1.9611e-01, -1.5209e-01, -1.3213e-01,  ..., -8.8608e-02,\n",
       "            -9.5087e-02, -9.4204e-02],\n",
       "           ...,\n",
       "           [-2.1004e-01, -1.6152e-01, -1.3824e-01,  ..., -1.2609e-01,\n",
       "            -1.2685e-01, -1.4150e-01],\n",
       "           [-2.1018e-01, -1.6164e-01, -1.3834e-01,  ..., -1.2611e-01,\n",
       "            -1.2695e-01, -1.4163e-01],\n",
       "           [-2.1018e-01, -1.6164e-01, -1.3834e-01,  ..., -1.2611e-01,\n",
       "            -1.2696e-01, -1.4163e-01]]],\n",
       " \n",
       " \n",
       "         [[[-4.1728e-01, -3.0843e-01, -2.2506e-01,  ..., -1.9419e-01,\n",
       "            -1.9818e-01, -1.7043e-01],\n",
       "           [-3.8290e-01, -2.9721e-01, -2.2075e-01,  ...,  2.6881e+00,\n",
       "             2.6645e+00,  2.7233e+00],\n",
       "           [-2.9914e-01, -2.8645e-01, -2.2247e-01,  ...,  1.0621e+01,\n",
       "             1.0491e+01,  9.6253e+00],\n",
       "           ...,\n",
       "           [-4.2024e-01, -3.0807e-01, -2.2448e-01,  ..., -1.9530e-01,\n",
       "            -1.9938e-01, -2.2843e-01],\n",
       "           [-4.2151e-01, -3.0870e-01, -2.2488e-01,  ..., -1.9533e-01,\n",
       "            -1.9938e-01, -2.2840e-01],\n",
       "           [-4.2218e-01, -3.0913e-01, -2.2524e-01,  ..., -1.9536e-01,\n",
       "            -1.9940e-01, -2.2843e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 5.9289e-01,  2.6300e-01,  9.2970e-04,  ..., -2.4890e-01,\n",
       "            -3.0482e-01, -2.9365e-01],\n",
       "           [ 2.3599e+00,  7.2730e-01,  2.6346e-02,  ..., -1.5109e-01,\n",
       "            -2.1938e-01, -2.0244e-01],\n",
       "           [ 3.2642e+00,  7.9539e+00,  9.5836e+00,  ...,  8.3796e+00,\n",
       "             6.4513e+00,  3.9080e+00],\n",
       "           ...,\n",
       "           [-2.7355e-01, -2.1488e-01, -1.7973e-01,  ..., -2.5073e-01,\n",
       "            -3.0727e-01, -3.3295e-01],\n",
       "           [-2.7384e-01, -2.1495e-01, -1.7974e-01,  ..., -2.5073e-01,\n",
       "            -3.0727e-01, -3.3295e-01],\n",
       "           [-2.7394e-01, -2.1498e-01, -1.7974e-01,  ..., -2.5073e-01,\n",
       "            -3.0727e-01, -3.3295e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 4.4312e+00,  2.6634e+00,  2.8036e+00,  ..., -4.6592e-01,\n",
       "            -2.9583e-01, -2.9333e-01],\n",
       "           [ 7.6223e+00,  5.8898e+00,  7.1731e+00,  ..., -4.6579e-01,\n",
       "            -2.9581e-01, -2.9329e-01],\n",
       "           [ 2.1609e+00,  1.7834e-01, -2.5316e-01,  ..., -4.6458e-01,\n",
       "            -2.9544e-01, -2.9120e-01],\n",
       "           ...,\n",
       "           [-3.4881e-01, -3.0436e-01, -3.1163e-01,  ..., -4.6354e-01,\n",
       "            -2.9473e-01, -2.9219e-01],\n",
       "           [-3.4774e-01, -3.0392e-01, -3.1270e-01,  ..., -4.6585e-01,\n",
       "            -2.9576e-01, -2.9315e-01],\n",
       "           [-3.5371e-01, -3.0787e-01, -3.1493e-01,  ..., -4.6647e-01,\n",
       "            -2.9615e-01, -2.9345e-01]]]]),\n",
       " 'mfccs': tensor([[[[-3.2019e+00, -3.0747e+00, -3.1315e+00,  ..., -2.9134e+00,\n",
       "            -2.8071e+00, -2.6154e+00],\n",
       "           [ 1.3768e+00,  1.5647e+00,  1.4285e+00,  ...,  1.9932e+00,\n",
       "             2.0728e+00,  2.2737e+00],\n",
       "           [ 7.6284e-01,  9.0319e-01,  9.0167e-01,  ...,  4.8543e-01,\n",
       "             5.9446e-01,  5.6482e-01],\n",
       "           ...,\n",
       "           [ 1.4004e-01,  7.1885e-03, -5.4232e-02,  ..., -7.8918e-03,\n",
       "            -9.3063e-02, -9.5503e-02],\n",
       "           [ 6.4271e-02, -8.0439e-04, -2.0045e-02,  ..., -8.0804e-02,\n",
       "            -1.2601e-01, -9.7851e-02],\n",
       "           [ 9.6982e-03, -7.7829e-02, -7.8620e-02,  ...,  3.5720e-02,\n",
       "             2.6859e-02, -1.3108e-01]]],\n",
       " \n",
       " \n",
       "         [[[-2.5559e+00, -1.2249e+00, -9.5350e-01,  ..., -1.4432e+00,\n",
       "            -1.5306e+00, -1.4350e+00],\n",
       "           [ 2.3902e+00,  3.1008e+00,  3.1448e+00,  ...,  2.4665e+00,\n",
       "             2.5218e+00,  2.5634e+00],\n",
       "           [-3.5816e-02, -1.9534e-01, -2.7140e-01,  ..., -6.0152e-01,\n",
       "            -5.4920e-01, -3.6849e-01],\n",
       "           ...,\n",
       "           [ 5.0297e-02, -6.9241e-02, -1.1796e-01,  ..., -1.3846e-01,\n",
       "            -5.2036e-02,  1.2407e-01],\n",
       "           [-2.3047e-01, -4.7530e-01, -6.1127e-01,  ...,  1.2666e-01,\n",
       "             5.9919e-02, -5.9600e-03],\n",
       "           [-8.8118e-02, -3.4774e-01, -4.0999e-01,  ..., -5.3110e-01,\n",
       "            -4.9625e-01, -5.7930e-01]]],\n",
       " \n",
       " \n",
       "         [[[-3.2454e+00, -3.1103e+00, -3.0929e+00,  ..., -2.8252e+00,\n",
       "            -2.6667e+00, -2.6206e+00],\n",
       "           [ 1.4368e+00,  1.7278e+00,  1.7679e+00,  ...,  1.9793e+00,\n",
       "             2.1576e+00,  2.2596e+00],\n",
       "           [ 2.8840e-01,  2.9494e-01,  2.4169e-01,  ..., -3.2709e-01,\n",
       "            -5.0850e-01, -4.9909e-01],\n",
       "           ...,\n",
       "           [ 6.1032e-02,  3.6279e-02,  6.5259e-02,  ..., -4.2247e-02,\n",
       "             4.4530e-02,  1.0523e-01],\n",
       "           [-3.5469e-03, -7.4470e-02, -6.7963e-02,  ..., -8.3184e-02,\n",
       "            -8.2336e-02, -1.0316e-01],\n",
       "           [ 9.2876e-02, -9.7720e-03, -6.9436e-03,  ...,  5.1594e-02,\n",
       "            -2.7143e-03, -9.7816e-02]]],\n",
       " \n",
       " \n",
       "         [[[-2.8594e+00,  1.5159e+00,  1.9885e+00,  ...,  1.0636e+00,\n",
       "             3.8193e-01, -9.8615e-02],\n",
       "           [ 1.1655e+00,  1.4791e+00,  1.6833e+00,  ...,  2.4584e+00,\n",
       "             1.7313e+00,  1.4168e+00],\n",
       "           [-6.4705e-01, -1.5180e+00, -1.3806e+00,  ..., -1.9946e+00,\n",
       "            -2.7560e+00, -2.7045e+00],\n",
       "           ...,\n",
       "           [ 2.5808e-01, -9.2396e-02, -4.1257e-01,  ..., -8.4538e-02,\n",
       "             1.0976e-01,  2.6632e-01],\n",
       "           [ 2.4628e-01,  5.9259e-02,  9.7313e-02,  ..., -3.5481e-01,\n",
       "            -1.6578e-01, -1.6129e-01],\n",
       "           [ 3.9697e-01,  1.9282e-01,  2.0814e-01,  ...,  3.8447e-02,\n",
       "             8.7460e-02, -1.2969e-01]]]]),\n",
       " 'chroma': tensor([[[[-0.7567, -0.5582, -0.4656,  ..., -0.4556, -0.4080, -0.5075],\n",
       "           [-0.4803, -0.4413, -0.4249,  ..., -0.4461, -0.2159, -0.2644],\n",
       "           [ 0.4408,  0.2230,  0.0331,  ..., -0.5843, -0.5005, -0.4754],\n",
       "           ...,\n",
       "           [-0.8944, -0.5833, -0.4656,  ...,  2.2661,  2.2598,  2.7796],\n",
       "           [-0.8612, -0.5761, -0.4609,  ..., -0.2342, -0.2968,  0.3481],\n",
       "           [-0.8470, -0.5838, -0.4705,  ..., -0.5168, -0.5094, -0.4754]]],\n",
       " \n",
       " \n",
       "         [[[-0.8111, -0.8727, -0.7707,  ...,  0.8742,  0.7590,  0.1815],\n",
       "           [-1.0177, -0.9029, -0.7425,  ..., -0.1514,  0.2178, -0.0825],\n",
       "           [-0.2178,  0.6279,  0.5649,  ..., -0.4260,  0.3772, -0.3812],\n",
       "           ...,\n",
       "           [-0.7224, -0.8819, -0.7516,  ..., -1.2205, -1.0018, -0.9107],\n",
       "           [-0.7952, -0.7875, -0.6589,  ..., -0.3807,  0.1445, -0.5470],\n",
       "           [-0.4569, -0.1565, -0.0745,  ...,  0.5529,  0.1156,  0.1805]]],\n",
       " \n",
       " \n",
       "         [[[ 0.3385, -0.2014, -0.3642,  ..., -0.5794, -0.6460, -0.7051],\n",
       "           [ 1.2067,  1.2384,  0.8681,  ...,  0.3965,  0.1821,  0.0400],\n",
       "           [ 1.7631,  2.3597,  2.6017,  ...,  2.5186,  2.3553,  2.1819],\n",
       "           ...,\n",
       "           [ 1.4429,  0.3295,  0.2298,  ...,  1.5393,  1.8875,  2.0416],\n",
       "           [-0.4269, -0.7063, -0.6448,  ..., -0.4571, -0.2667,  0.0157],\n",
       "           [-0.6274, -0.8347, -0.7809,  ..., -0.7812, -0.7219, -0.4779]]],\n",
       " \n",
       " \n",
       "         [[[ 0.6282,  0.9281,  1.4224,  ..., -1.0387, -0.6503, -0.5051],\n",
       "           [ 2.7596,  2.6608,  2.4097,  ...,  0.5983,  0.1636, -0.6153],\n",
       "           [ 1.0034,  1.1724,  1.0511,  ..., -0.4461, -0.3124, -0.6728],\n",
       "           ...,\n",
       "           [-0.9126, -0.7533, -0.6742,  ..., -0.2902, -0.6492, -0.3090],\n",
       "           [-0.8702, -0.6513, -0.5731,  ..., -0.4682, -0.6240,  0.0154],\n",
       "           [-0.5994, -0.5048, -0.5095,  ..., -1.3681, -0.8671, -0.7507]]]]),\n",
       " 'spectral_contrast': tensor([[[[-1.1086, -0.9208, -0.5217,  ...,  0.4689, -0.5474, -1.6316],\n",
       "           [-0.7304, -0.8678, -0.5357,  ..., -0.2418, -0.9681,  1.3794],\n",
       "           [-0.1034, -0.1520, -0.0737,  ..., -0.3305,  0.9843,  0.5752],\n",
       "           ...,\n",
       "           [-0.0055,  0.0659, -0.1354,  ..., -0.8511,  0.6594,  0.9798],\n",
       "           [-0.2232, -0.1633, -0.5732,  ..., -0.8742, -0.6531, -0.0318],\n",
       "           [ 2.2730,  2.2973,  2.4025,  ...,  2.2281,  1.6400, -1.0451]]],\n",
       " \n",
       " \n",
       "         [[[-0.2477, -0.2820, -0.0435,  ...,  0.3961,  1.6773, -0.6762],\n",
       "           [-0.8557, -0.5778, -0.9385,  ..., -0.6488, -1.2409,  0.8481],\n",
       "           [-0.8144, -1.0375, -0.6401,  ..., -0.5844,  0.4500, -0.8835],\n",
       "           ...,\n",
       "           [-0.2078, -0.3620, -0.3092,  ..., -0.6762,  0.1619,  0.3977],\n",
       "           [ 0.2624,  0.1600, -0.0997,  ..., -0.2082,  0.6903,  1.8165],\n",
       "           [ 2.2909,  2.3046,  2.3458,  ...,  2.2922, -0.4055, -1.2290]]],\n",
       " \n",
       " \n",
       "         [[[-0.4336, -0.7802, -0.2891,  ..., -0.2594,  0.1054, -0.5045],\n",
       "           [-0.7153, -0.7695, -0.2575,  ..., -0.7265, -0.2960,  0.5468],\n",
       "           [-0.7698, -0.1599, -0.3962,  ...,  0.3641,  1.0625,  0.0178],\n",
       "           ...,\n",
       "           [-0.0308, -0.0534, -0.5395,  ..., -1.0564, -0.3355,  0.8577],\n",
       "           [-0.2158, -0.3972, -0.9208,  ..., -0.3286,  0.6750, -0.1540],\n",
       "           [ 2.3703,  2.3607,  2.3562,  ...,  2.2352, -2.1008, -2.0243]]],\n",
       " \n",
       " \n",
       "         [[[-0.7952, -0.5575, -0.0312,  ...,  0.1257,  0.4113,  0.9080],\n",
       "           [-0.7985,  0.0062, -0.7157,  ..., -0.5041,  0.7552, -0.6713],\n",
       "           [ 0.1076, -0.0416, -0.2455,  ..., -0.6646, -1.5234, -0.6820],\n",
       "           ...,\n",
       "           [-0.4030, -0.7581, -0.4212,  ..., -0.2760,  0.4587,  0.5487],\n",
       "           [-0.1379, -0.5204, -0.5022,  ..., -0.4263, -1.2671,  0.3319],\n",
       "           [ 2.3331,  2.3659,  2.4004,  ...,  2.3739,  1.4326, -1.7594]]]]),\n",
       " 'zcr': tensor([[[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.]]]),\n",
       " 'spectral_centroid': tensor([[[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.]]]),\n",
       " 'spectral_bandwidth': tensor([[[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.]]]),\n",
       " 'rms_energy': tensor([[[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.]]]),\n",
       " 'tonnetz': tensor([[[[-0.8616, -1.4090, -1.6224,  ...,  0.0844,  0.5306,  0.8800],\n",
       "           [-1.0522, -0.6396, -0.4733,  ..., -1.1211, -0.9750, -0.8526],\n",
       "           [ 1.6558,  1.5899,  1.4420,  ..., -1.4157, -1.6872, -1.7998],\n",
       "           [-0.8036, -0.5435, -0.3890,  ...,  0.9807,  0.9212,  0.5619],\n",
       "           [ 0.2151,  0.1270,  0.0915,  ...,  0.1498,  0.1928,  0.2804],\n",
       "           [ 0.8466,  0.8753,  0.9512,  ...,  1.3219,  1.0176,  0.9301]]],\n",
       " \n",
       " \n",
       "         [[[ 0.9643,  1.5225,  1.5840,  ..., -1.1864, -1.3839, -0.8609],\n",
       "           [-0.7485, -0.9579, -0.9999,  ...,  1.1871,  1.2194,  0.5271],\n",
       "           [ 1.5903,  0.9446,  0.9660,  ..., -0.5149, -0.3204, -0.3941],\n",
       "           [-0.4604,  0.1174, -0.0694,  ...,  1.4641,  1.3178,  1.9813],\n",
       "           [-0.0158, -0.2959, -0.2625,  ..., -0.8769, -0.8703, -0.8660],\n",
       "           [-1.3299, -1.3308, -1.2183,  ..., -0.0730,  0.0374, -0.3873]]],\n",
       " \n",
       " \n",
       "         [[[ 0.7275,  0.9260,  1.0471,  ...,  1.2285,  1.1946,  1.0423],\n",
       "           [ 0.9094,  0.8611,  0.8688,  ...,  0.8239,  0.9024,  0.9595],\n",
       "           [ 0.7876,  0.5490,  0.3871,  ...,  0.0705, -0.0737,  0.0509],\n",
       "           [-1.8921, -1.9167, -1.8904,  ..., -1.8523, -1.8522, -1.9172],\n",
       "           [-0.6545, -0.6208, -0.6188,  ..., -0.5474, -0.4780, -0.4586],\n",
       "           [ 0.1221,  0.2014,  0.2061,  ...,  0.2768,  0.3069,  0.3232]]],\n",
       " \n",
       " \n",
       "         [[[-1.1885, -1.4077, -1.6266,  ...,  0.0504, -0.3143, -0.2486],\n",
       "           [-1.2361, -1.2306, -0.2197,  ...,  0.9800,  1.7487,  1.8639],\n",
       "           [ 1.5516,  0.5208,  1.7628,  ..., -2.0204, -1.1953, -1.2149],\n",
       "           [ 0.7873,  1.2001,  0.3783,  ...,  0.9233,  0.8098,  0.5726],\n",
       "           [ 0.1623,  0.8899, -0.0701,  ...,  0.2573, -0.2017, -0.1809],\n",
       "           [-0.0766,  0.0274, -0.2248,  ..., -0.1905, -0.8473, -0.7921]]]]),\n",
       " 'bit_rate': tensor([-1.2260, -0.1709, -2.3653, -1.7535]),\n",
       " 'duration': tensor([-0.2560, -1.1944, -0.2560,  0.3344]),\n",
       " 'genre': tensor([17., 10., 17., 21.]),\n",
       " 'success': tensor([[1., 0., 0.],\n",
       "         [1., 0., 0.],\n",
       "         [1., 0., 0.],\n",
       "         [0., 0., 1.]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mel_spectrogram': tensor([[[[ 5.4300e-01, -1.3056e-02, -3.4545e-01,  ...,  4.5275e+00,\n",
       "             4.8355e+00,  4.0502e+00],\n",
       "           [ 8.1361e-01,  1.5389e+00,  2.4137e+00,  ...,  9.5538e+00,\n",
       "             9.0293e+00,  9.5469e+00],\n",
       "           [ 6.9433e-03,  4.5246e-01,  1.0315e+00,  ...,  1.3538e+00,\n",
       "             2.2285e+00,  2.3764e+00],\n",
       "           ...,\n",
       "           [-4.9072e-01, -4.7271e-01, -3.9973e-01,  ..., -2.1744e-01,\n",
       "            -2.3119e-01, -2.1707e-01],\n",
       "           [-4.9214e-01, -4.7399e-01, -4.0036e-01,  ..., -2.1744e-01,\n",
       "            -2.3119e-01, -2.1707e-01],\n",
       "           [-4.9314e-01, -4.7473e-01, -4.0091e-01,  ..., -2.1744e-01,\n",
       "            -2.3119e-01, -2.1707e-01]]],\n",
       " \n",
       " \n",
       "         [[[-7.2179e-02, -1.7516e-01, -1.4741e-01,  ..., -1.0940e-01,\n",
       "            -1.0917e-01, -1.0906e-01],\n",
       "           [-1.0820e-01, -1.7101e-01, -1.4117e-01,  ..., -1.0962e-01,\n",
       "            -1.0975e-01, -1.0990e-01],\n",
       "           [-1.4134e-01, -2.0539e-01, -1.4204e-01,  ..., -1.0986e-01,\n",
       "            -1.0998e-01, -1.1003e-01],\n",
       "           ...,\n",
       "           [-1.5763e-01, -2.2994e-01, -1.5193e-01,  ..., -1.0990e-01,\n",
       "            -1.1004e-01, -1.1036e-01],\n",
       "           [-1.5764e-01, -2.2994e-01, -1.5193e-01,  ..., -1.0990e-01,\n",
       "            -1.1004e-01, -1.1036e-01],\n",
       "           [-1.5764e-01, -2.2994e-01, -1.5193e-01,  ..., -1.0990e-01,\n",
       "            -1.1004e-01, -1.1036e-01]]],\n",
       " \n",
       " \n",
       "         [[[-3.3183e-01, -2.6065e-01, -2.2711e-01,  ..., -2.2746e-01,\n",
       "            -2.0029e-01, -1.8679e-01],\n",
       "           [-3.3126e-01, -2.6047e-01, -2.2705e-01,  ..., -2.2622e-01,\n",
       "            -1.9968e-01, -1.8655e-01],\n",
       "           [-3.2786e-01, -2.5978e-01, -2.2631e-01,  ..., -2.2679e-01,\n",
       "            -1.9964e-01, -1.8607e-01],\n",
       "           ...,\n",
       "           [-3.3204e-01, -2.6080e-01, -2.2724e-01,  ..., -2.2787e-01,\n",
       "            -2.0056e-01, -1.8699e-01],\n",
       "           [-3.3205e-01, -2.6081e-01, -2.2724e-01,  ..., -2.2787e-01,\n",
       "            -2.0056e-01, -1.8699e-01],\n",
       "           [-3.3205e-01, -2.6081e-01, -2.2724e-01,  ..., -2.2788e-01,\n",
       "            -2.0056e-01, -1.8699e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 2.2435e-02, -7.3422e-02, -2.3880e-01,  ..., -1.3629e-01,\n",
       "            -1.2812e-01, -1.3823e-01],\n",
       "           [ 1.7798e-01,  2.6453e-01,  5.2492e-03,  ...,  4.6175e-02,\n",
       "            -7.3087e-02, -7.9530e-02],\n",
       "           [ 1.2866e+00,  8.6690e-01,  4.1802e-01,  ...,  1.0165e+01,\n",
       "             1.0482e+01,  1.0040e+01],\n",
       "           ...,\n",
       "           [-1.7050e-01, -1.9543e-01, -2.6870e-01,  ..., -1.3767e-01,\n",
       "            -1.3124e-01, -1.4417e-01],\n",
       "           [-1.7050e-01, -1.9544e-01, -2.6873e-01,  ..., -1.3767e-01,\n",
       "            -1.3124e-01, -1.4417e-01],\n",
       "           [-1.7050e-01, -1.9544e-01, -2.6876e-01,  ..., -1.3767e-01,\n",
       "            -1.3124e-01, -1.4417e-01]]]]),\n",
       " 'mfccs': tensor([[[[-2.8073e+00, -1.1962e+00, -5.5802e-01,  ..., -2.9075e+00,\n",
       "            -2.9197e+00, -2.9416e+00],\n",
       "           [ 2.0847e+00,  3.1244e+00,  3.2521e+00,  ...,  2.0983e+00,\n",
       "             2.0828e+00,  2.0561e+00],\n",
       "           [-2.5115e-01, -6.2634e-01, -6.9433e-01,  ...,  1.9239e-01,\n",
       "             1.7522e-01,  1.6880e-01],\n",
       "           ...,\n",
       "           [ 3.7516e-01,  5.7406e-02, -3.0770e-01,  ...,  2.1186e-02,\n",
       "             5.5750e-02,  6.4700e-02],\n",
       "           [-8.0049e-03, -1.4991e-01, -1.4970e-01,  ...,  6.8608e-04,\n",
       "             9.5977e-03, -5.2678e-03],\n",
       "           [-1.1941e-01, -4.4037e-01, -4.0410e-01,  ...,  9.0818e-02,\n",
       "             1.0329e-01,  1.0650e-01]]],\n",
       " \n",
       " \n",
       "         [[[-3.4335e+00, -3.2364e+00, -2.9604e+00,  ..., -3.3154e+00,\n",
       "            -3.3383e+00, -3.3108e+00],\n",
       "           [ 5.5883e-01,  1.3216e+00,  1.8687e+00,  ...,  7.2394e-01,\n",
       "             6.8571e-01,  6.9041e-01],\n",
       "           [ 5.0125e-01,  7.5085e-01,  7.9660e-01,  ...,  5.9417e-01,\n",
       "             5.6069e-01,  4.7129e-01],\n",
       "           ...,\n",
       "           [ 2.1064e-01,  1.6370e-01,  1.4380e-01,  ...,  7.0025e-03,\n",
       "             3.0036e-02,  2.6301e-02],\n",
       "           [ 2.7183e-01,  2.2838e-01,  1.8309e-01,  ...,  2.3502e-01,\n",
       "             1.8121e-01,  2.4776e-01],\n",
       "           [ 3.2955e-01,  2.4932e-01,  1.5930e-01,  ...,  4.7193e-01,\n",
       "             4.4250e-01,  4.6576e-01]]],\n",
       " \n",
       " \n",
       "         [[[-2.0633e+00, -1.8821e+00, -1.9926e+00,  ..., -2.4446e+00,\n",
       "            -2.4445e+00, -2.3478e+00],\n",
       "           [ 2.8740e+00,  2.9799e+00,  2.9067e+00,  ...,  2.5908e+00,\n",
       "             2.5993e+00,  2.6800e+00],\n",
       "           [-1.2753e-01, -1.2736e-01, -5.0009e-02,  ..., -8.2900e-03,\n",
       "             2.3377e-02, -3.8058e-02],\n",
       "           ...,\n",
       "           [-4.3345e-02, -7.3021e-02,  1.3457e-02,  ..., -1.0775e-01,\n",
       "            -8.8377e-02, -4.5743e-02],\n",
       "           [ 2.7199e-01,  2.6619e-01,  2.1148e-01,  ...,  1.1228e-01,\n",
       "             2.1989e-01,  2.6128e-01],\n",
       "           [ 1.7469e-01,  7.6441e-02,  1.4666e-01,  ..., -2.2291e-01,\n",
       "            -1.6978e-01, -1.4299e-01]]],\n",
       " \n",
       " \n",
       "         [[[-3.1624e+00, -2.7962e+00, -2.6303e+00,  ..., -2.7471e+00,\n",
       "            -2.8191e+00, -2.8679e+00],\n",
       "           [ 1.5640e+00,  2.1660e+00,  2.2872e+00,  ...,  2.2637e+00,\n",
       "             2.1583e+00,  2.0904e+00],\n",
       "           [ 6.6330e-01,  5.6026e-01,  5.9237e-01,  ...,  1.4880e-02,\n",
       "             1.3289e-01,  2.5067e-01],\n",
       "           ...,\n",
       "           [ 2.0874e-02, -8.8527e-02, -1.4653e-01,  ..., -5.4570e-02,\n",
       "            -2.4895e-02, -1.3815e-02],\n",
       "           [ 7.6019e-02,  1.2879e-02,  2.4898e-02,  ..., -3.1970e-02,\n",
       "            -1.5492e-02, -1.1725e-02],\n",
       "           [ 7.2487e-02, -4.7664e-02, -4.7565e-02,  ..., -4.8030e-02,\n",
       "            -6.8524e-02, -9.7371e-02]]]]),\n",
       " 'chroma': tensor([[[[-1.1962, -1.1819, -0.8223,  ..., -0.9447, -1.0228, -1.0630],\n",
       "           [-0.4733, -0.9235, -0.8801,  ..., -0.7840, -1.0054, -1.1118],\n",
       "           [ 0.8877, -0.0288, -0.4002,  ..., -0.6104, -0.6239, -0.6394],\n",
       "           ...,\n",
       "           [-0.9372, -0.5796, -0.4132,  ..., -0.6209, -0.0410, -0.0745],\n",
       "           [-0.0816,  0.0462, -0.1033,  ...,  1.9168,  1.9634,  1.6752],\n",
       "           [-1.0387, -1.0237, -0.8891,  ..., -0.5902, -0.6529, -0.6081]]],\n",
       " \n",
       " \n",
       "         [[[-0.6082, -0.6953, -0.5073,  ..., -0.4106, -0.4103, -0.4142],\n",
       "           [-0.6081, -0.8251, -0.5340,  ..., -0.4106, -0.4103, -0.4142],\n",
       "           [-0.6089, -0.8678, -0.5429,  ..., -0.4106, -0.4103, -0.4142],\n",
       "           ...,\n",
       "           [ 0.2661,  1.6026,  2.9671,  ...,  3.2210,  3.2217,  3.2241],\n",
       "           [-0.3969,  0.9012,  0.7603,  ...,  0.3124,  0.3050,  0.2962],\n",
       "           [-0.5872, -0.2081, -0.3949,  ..., -0.4063, -0.4061, -0.4100]]],\n",
       " \n",
       " \n",
       "         [[[ 1.2483,  0.4969,  0.3290,  ..., -0.6647, -0.5664, -0.5141],\n",
       "           [-0.7654, -0.7454, -0.6194,  ..., -0.3127, -0.1622, -0.0231],\n",
       "           [ 0.9280,  0.2934,  0.2706,  ...,  3.0501,  3.1956,  3.2138],\n",
       "           ...,\n",
       "           [-0.5032, -0.5128, -0.5677,  ...,  0.5866, -0.0337, -0.2430],\n",
       "           [-0.9085, -0.8317, -0.7312,  ..., -0.5575, -0.5286, -0.4943],\n",
       "           [ 1.7346,  1.0231,  0.5455,  ..., -0.6901, -0.5816, -0.5335]]],\n",
       " \n",
       " \n",
       "         [[[ 1.1007,  2.6043,  2.8382,  ..., -0.0537,  0.2474,  0.3408],\n",
       "           [ 0.0853,  0.2703, -0.0610,  ..., -0.1324,  0.3026, -0.0820],\n",
       "           [-1.0023, -0.7565, -0.4442,  ...,  0.9292,  1.1270,  0.8095],\n",
       "           ...,\n",
       "           [ 0.9452, -0.2937, -0.7870,  ..., -0.8740, -0.9319, -0.9052],\n",
       "           [ 1.3552, -0.0824, -0.7559,  ..., -0.0904, -0.3805, -0.1626],\n",
       "           [ 1.4401,  1.4108,  0.5408,  ..., -0.5037, -0.6065, -0.5886]]]]),\n",
       " 'spectral_contrast': tensor([[[[-0.3879, -0.7553, -0.6334,  ..., -0.2949,  0.1989,  0.6742],\n",
       "           [-0.5450, -0.7480, -0.5003,  ..., -0.5654, -0.5356,  0.1723],\n",
       "           [-0.6247, -0.0838,  0.1534,  ..., -0.5953, -0.8270,  0.7789],\n",
       "           ...,\n",
       "           [-0.1890, -0.1260, -0.4589,  ...,  0.4386,  0.2359,  0.6139],\n",
       "           [-0.0585, -0.3007, -0.4432,  ..., -1.3423, -1.3193, -1.4041],\n",
       "           [ 2.4015,  2.3724,  2.3810,  ...,  2.0345,  2.0370, -1.6849]]],\n",
       " \n",
       " \n",
       "         [[[-1.0421, -0.8204, -0.8245,  ..., -0.8769, -1.0200, -0.6747],\n",
       "           [-0.2653, -0.6131, -0.7492,  ..., -0.7353, -0.5943, -0.0381],\n",
       "           [ 0.9392, -0.4142,  0.0102,  ...,  1.2791,  1.4788,  1.8026],\n",
       "           ...,\n",
       "           [-0.4689, -0.2488, -0.5321,  ...,  0.4895,  0.1503,  0.6545],\n",
       "           [-0.6142, -0.2981, -0.3429,  ..., -0.3845, -0.4434,  0.5292],\n",
       "           [ 2.0124,  2.3724,  2.3113,  ...,  1.4633,  1.4610, -1.1600]]],\n",
       " \n",
       " \n",
       "         [[[ 1.4750, -0.0462, -0.2744,  ...,  0.2729,  0.4386,  1.7640],\n",
       "           [-1.7601, -1.2989, -0.7921,  ..., -0.6030, -1.1081, -0.8382],\n",
       "           [-0.9333, -0.3929, -0.2185,  ..., -0.0475,  0.3217,  1.3009],\n",
       "           ...,\n",
       "           [ 0.2466, -0.5773, -0.6194,  ..., -0.7072, -0.5341, -0.2478],\n",
       "           [ 0.4524,  0.0558, -0.4975,  ..., -0.8973, -0.7538, -0.5874],\n",
       "           [-0.2172,  0.0651,  2.3701,  ...,  2.2736,  2.0995, -0.9393]]],\n",
       " \n",
       " \n",
       "         [[[-0.3627, -0.6200, -0.4406,  ..., -0.2829,  0.2437,  0.3369],\n",
       "           [-0.9796, -0.6902, -0.2964,  ..., -1.0031, -1.2561, -0.0595],\n",
       "           [-0.2196,  0.0317,  0.2202,  ..., -0.5829, -0.4781,  0.9080],\n",
       "           ...,\n",
       "           [-0.3027, -0.4661, -0.5190,  ..., -0.2095, -0.1261,  0.7281],\n",
       "           [-0.3976, -0.5699, -0.7935,  ...,  0.1278,  0.3927, -0.1293],\n",
       "           [ 2.3665,  2.3651,  2.3460,  ...,  2.3191,  2.0637, -2.2921]]]]),\n",
       " 'zcr': tensor([[[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.]]]),\n",
       " 'spectral_centroid': tensor([[[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.]]]),\n",
       " 'spectral_bandwidth': tensor([[[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.]]]),\n",
       " 'rms_energy': tensor([[[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.]]]),\n",
       " 'tonnetz': tensor([[[[-1.3391, -1.7869, -1.7831,  ..., -1.6381, -1.6193, -1.5788],\n",
       "           [-0.4736, -0.5615, -0.5654,  ...,  0.4438,  0.4006,  0.2943],\n",
       "           [ 0.6475,  1.1476,  1.0191,  ...,  1.6320,  1.6604,  1.7251],\n",
       "           [ 1.8254,  1.0425,  1.1277,  ..., -0.6548, -0.6604, -0.6502],\n",
       "           [-0.4113, -0.1150, -0.1908,  ...,  0.1542,  0.1285,  0.1028],\n",
       "           [-0.2489,  0.2734,  0.3927,  ...,  0.0629,  0.0902,  0.1068]]],\n",
       " \n",
       " \n",
       "         [[[ 0.6835,  0.4864,  1.2263,  ...,  1.5124,  1.5115,  1.5075],\n",
       "           [ 0.9318,  1.3099,  0.1789,  ..., -0.1409, -0.1479, -0.1363],\n",
       "           [ 0.1606,  0.5929, -2.0119,  ..., -1.7970, -1.7972, -1.7999],\n",
       "           [ 0.7485, -0.1209, -0.0688,  ..., -0.1288, -0.1180, -0.1169],\n",
       "           [-0.5945, -0.3897,  0.0349,  ..., -0.1057, -0.1098, -0.1188],\n",
       "           [-1.9300, -1.8787,  0.6407,  ...,  0.6600,  0.6614,  0.6644]]],\n",
       " \n",
       " \n",
       "         [[[ 1.9229,  1.7353,  1.9563,  ...,  1.6838,  1.7277,  1.6667],\n",
       "           [-1.0107, -1.2273, -0.5598,  ...,  0.9488,  0.9258,  0.9768],\n",
       "           [ 0.4649,  0.2848, -0.0649,  ..., -0.9726, -0.7653, -0.7394],\n",
       "           [ 0.0305,  0.6247,  0.4706,  ..., -0.9463, -1.0992, -1.1960],\n",
       "           [-0.8950, -0.6520, -0.9712,  ..., -0.6470, -0.5569, -0.4954],\n",
       "           [-0.5126, -0.7656, -0.8310,  ..., -0.0667, -0.2320, -0.2127]]],\n",
       " \n",
       " \n",
       "         [[[-0.7687, -1.2826, -1.4720,  ..., -1.9657, -1.9716, -1.9550],\n",
       "           [ 0.2374,  0.6510,  0.9421,  ...,  0.5695,  0.6696,  0.7538],\n",
       "           [ 0.4103,  0.5628,  0.5403,  ...,  1.2168,  1.1373,  1.0994],\n",
       "           [ 1.8845,  1.5340,  1.2566,  ..., -0.2126, -0.1926, -0.2202],\n",
       "           [-1.0793, -1.0393, -1.0021,  ..., -0.1274, -0.1887, -0.2269],\n",
       "           [-0.6842, -0.4258, -0.2649,  ...,  0.5194,  0.5460,  0.5489]]]]),\n",
       " 'bit_rate': tensor([ 0.8842, -0.6984,  0.8842,  0.8842]),\n",
       " 'duration': tensor([ 0.9354, -0.1190,  0.0919, -0.1928]),\n",
       " 'genre': tensor([1235.,   38.,   17., 1235.]),\n",
       " 'success': tensor([[0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.]])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
